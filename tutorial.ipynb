{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graphAttack Tutorial #01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial demonstrates the basic graph framework used in graphAttack and applies it to a simple linear model\n",
    "\n",
    "You should be familiar with basic linear algebra, Python and the Jupyter Notebook editor. It also helps if you have a basic understanding of Machine Learning and classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import graphAttack as ga\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was developed using Python 3.6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graphAttack uses Nodes ot store data instead of normal python variables, the Nodes are classified into"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those objects are used to store numerical data to be fed into the graph. They use numpy arrays to store data. Here we initialize some variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([2])\n",
    "b = np.array([3])\n",
    "\n",
    "aVar = ga.Variable(a)\n",
    "bVar = ga.Variable(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now extract the stored data by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "aData = aVar.getValue()\n",
    "print(aVar.getValue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and print the information about a variable by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Variable with outputs: ()>\n"
     ]
    }
   ],
   "source": [
    "print(aVar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operatins usually take as input other Nodes (Variables or Operations) and can be used to extract the output of underlying mathematical operation. Lets start with simple addition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addOp = ga.AddOperation(aVar, bVar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can obtain the value of the operation by .getValue() as well as some information about it by printing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 3 =  [5]\n",
      "Details of addOp: <AddOperation with inputs: (Variable, Variable) and outputs: ()>\n"
     ]
    }
   ],
   "source": [
    "print(\"2 + 3 = \", addOp.getValue())\n",
    "print(\"Details of addOp:\", addOp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining operations could also be done using operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 3 =  [5]\n",
      "Details of addOp2: <AddOperation with inputs: (Variable, Variable) and outputs: ()>\n"
     ]
    }
   ],
   "source": [
    "addOp2 = aVar + bVar\n",
    "print(\"2 + 3 = \", addOp2.getValue())\n",
    "print(\"Details of addOp2:\", addOp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could chain operations together to get something slightly more complicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2 + 3) * 4 =  [20]\n"
     ]
    }
   ],
   "source": [
    "aVar = ga.Variable(np.array([2]))\n",
    "bVar = ga.Variable(np.array([3]))\n",
    "cVar = ga.Variable(np.array([4]))\n",
    "\n",
    "addOp = ga.AddOperation(aVar, bVar)\n",
    "multOp = ga.MultiplyOperation(addOp, cVar)\n",
    "\n",
    "print(\"(2 + 3) * 4 = \", multOp.getValue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, same could be achieved wiht operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2 + 3) * 4 =  [20]\n"
     ]
    }
   ],
   "source": [
    "aVar = ga.Variable(np.array([2]))\n",
    "bVar = ga.Variable(np.array([3]))\n",
    "cVar = ga.Variable(np.array([4]))\n",
    "\n",
    "addOp = aVar + bVar\n",
    "multOp = addOp * cVar\n",
    "\n",
    "print(\"(2 + 3) * 4 = \", multOp.getValue())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The complete list of supported operators is:\n",
    "\n",
    "+ : AddOperation\n",
    "@ : MatMatmulOperation\n",
    "* : MultiplyOperation\n",
    "/ : DivideOperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graphAttack supports automatic differentiation to ease up the burden of optimising your parameters, lets look at our previous example, however this time, we could ask for a derevative of one of the Variables with respect to the final operation of the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2 + 3) * 4 =  [20]\n",
      "The derevatve with respect to cVar is: [ 5.]\n"
     ]
    }
   ],
   "source": [
    "aVar = ga.Variable(np.array([2]))\n",
    "bVar = ga.Variable(np.array([3]))\n",
    "cVar = ga.Variable(np.array([4]))\n",
    "\n",
    "addOp = aVar + bVar\n",
    "multOp = addOp * cVar\n",
    "\n",
    "print(\"(2 + 3) * 4 = \", multOp.getValue())\n",
    "print(\"The derevatve with respect to cVar is:\", cVar.getGradient())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time we ask for a gradient, it looks for the derevatives up the operations chain untill it reaches a dead end and then uses a chain rule to propagate the gradients backwards through the whole graph. Normally we would ask for derevatives of variables but we also could find the derevative of an individual operations as long as we provide the input with repsect to which we want the derivation to be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The derevatve of multOp respect to cVar is: [ 5.]\n"
     ]
    }
   ],
   "source": [
    "print(\"The derevatve of multOp respect to cVar is:\", multOp.getGradient(cVar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite an important part of this library is the graph object, it helps store and organise your operations, it can be initialized by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mainGraph = ga.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add more operations to it using the .addOperation method, it has a couple of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addOperationDUMMY(self,\n",
    "                     operation,\n",
    "                     doGradient=False,\n",
    "                     finalOperation=False,\n",
    "                     feederOperation=False):\n",
    "    \"\"\"Add an operation ot the graph\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    operation : ga.Operation\n",
    "        Operation or Variable to be added\n",
    "    doGradient : bool\n",
    "        When true, calculate the derevative of the final operation with respect to this\n",
    "        operation when self.getGradients() is called\n",
    "    finalOperation : bool\n",
    "        When true, specify this operation as final of the graph\n",
    "    feederOperation : bool\n",
    "        When true, specify this operation as the data feeder operation\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ga.Operation\n",
    "        the handle for added operation\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        Graph can only provide gradients with respect to variables!\n",
    "        Only variables can be feeders\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We could compose our previous example using a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation Graph:\n",
      "<op0-Variable with outputs: (op2-AddOperation, )>\n",
      "<op1-Variable with outputs: (op2-AddOperation, )>\n",
      "<op2-AddOperation with inputs: (op0-Variable, op1-Variable) and outputs: (op4-MultiplyOperation, )>\n",
      "<op3-Variable with outputs: (op4-MultiplyOperation, )>\n",
      "<op4-MultiplyOperation with inputs: (op2-AddOperation, op3-Variable) and outputs: ()>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mainGraph = ga.Graph()\n",
    "\n",
    "a = np.array([2])\n",
    "b = np.array([3])\n",
    "c = np.array([4])\n",
    "\n",
    "aVar = mainGraph.addOperation(ga.Variable(a), doGradient=True)\n",
    "bVar = mainGraph.addOperation(ga.Variable(b), doGradient=True)\n",
    "addOp = mainGraph.addOperation(aVar + bVar)\n",
    "cVar = mainGraph.addOperation(ga.Variable(c), doGradient=True)\n",
    "multOp = mainGraph.addOperation(addOp * cVar, finalOperation=True)\n",
    "\n",
    "print(mainGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We cana now ask for Value of the final operation and gradients with respect to the specified variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final value of (2 + 3) * 4 =  [20]\n",
      "Gradients are:\n",
      "(0, 'op0-Variable', array([ 4.]))\n",
      "(1, 'op1-Variable', array([ 4.]))\n",
      "(3, 'op3-Variable', array([ 5.]))\n"
     ]
    }
   ],
   "source": [
    "print(\"Final value of (2 + 3) * 4 = \", mainGraph.getValue())\n",
    "print(\"Gradients are:\")\n",
    "for g in mainGraph.getGradients():\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to use the library to run a simple linear regression model that will extract the function:\n",
    "y = 2 * x1 + 3 * x2 + 4\n",
    "\n",
    "Initially we need to prepare the dataset in the rights shapes, the shapes are important and it is worth to keep track of them since often in python column vectors end up being row vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((100, 2))\n",
    "y = (x[:, 0] * 2 + x[:, 1] * 3 + 4).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to compose a graph that will represent our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.16786996]\n",
      " [ 0.11129035]] [ 0.02665591]\n",
      "Computation Graph:\n",
      "<op0-Variable with outputs: (op2-MatMatmulOperation, )>\n",
      "<op1-Variable with outputs: (op2-MatMatmulOperation, )>\n",
      "<op2-MatMatmulOperation with inputs: (op0-Variable, op1-Variable) and outputs: (op4-AddOperation, )>\n",
      "<op3-Variable with outputs: (op4-AddOperation, )>\n",
      "<op4-AddOperation with inputs: (op2-MatMatmulOperation, op3-Variable) and outputs: (op5-QuadratiCcostOperation, )>\n",
      "<op5-QuadratiCcostOperation with input: (op4-AddOperation) and outputs: ()>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mainGraph = ga.Graph()\n",
    "\n",
    "w = np.random.random((1, 2)).T\n",
    "b = np.random.random(1)\n",
    "\n",
    "print(w, b)\n",
    "feed = mainGraph.addOperation(ga.Variable(x), feederOperation=True)\n",
    "wop = mainGraph.addOperation(ga.Variable(w), doGradient=True)\n",
    "matmulop = mainGraph.addOperation(feed @ wop)\n",
    "bop = mainGraph.addOperation(ga.Variable(b), doGradient=True)\n",
    "addop = mainGraph.addOperation(matmulop + bop)\n",
    "costop = mainGraph.addOperation(ga.QuadratiCcostOperation(addop, y), finalOperation=True)\n",
    "\n",
    "print(mainGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the cost and gradients with respect to our parameters by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 20.2874106085\n",
      "100\n",
      "Gradients are:\n",
      "(1, 'op1-Variable', array([[-2.97423341],\n",
      "       [-3.49364679]]))\n",
      "(3, 'op3-Variable', array([-6.30036239]))\n"
     ]
    }
   ],
   "source": [
    "print(\"Cost:\", mainGraph.getValue())\n",
    "print(costop.nExamples)\n",
    "print(\"Gradients are:\")\n",
    "for g in mainGraph.getGradients():\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can figure out that the random parameters are not terrific, in order to optimize them we need ot construct a function that would return cost and flattened gradients so that we can feed it into a minimizer of choice, the code below is explained soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fprime(p, data, labels):\n",
    "    mainGraph.feederOperation.assignData(data)\n",
    "    mainGraph.costOperation.assignLabels(labels)\n",
    "    mainGraph.attachParameters(p)\n",
    "    mainGraph.resetAll()\n",
    "    c = mainGraph.getValue()\n",
    "    mainGraph.getGradients()\n",
    "    g = mainGraph.unrollGradients()\n",
    "    return c, g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function fprime takes as input a flattened vector of parameters, the data and labels. While data and labels are quite self-explanatory, lets discuss the parameters vector. It is a flattened vector containing all the weigths and biases. It can be extracted from a graph by calling mainGraph.unrollGraientParameters() and attached to a graph (values of weigths/biases variables updated) by mainGraph.attachParameters(p).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current parameters [[ 0.16786996]\n",
      " [ 0.11129035]] [ 0.02665591]\n",
      "Unrolled parameters [ 0.16786996  0.11129035  0.02665591]\n"
     ]
    }
   ],
   "source": [
    "print(\"Current parameters\", wop.getValue(), bop.getValue())\n",
    "param0 = mainGraph.unrollGradientParameters()\n",
    "print(\"Unrolled parameters\", param0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the function, we assign the data to the feeder Variable, assign labels to the cost Variable, attach provided parameters and reset the values of all operations (not Variables) so that the flow can be re-computed. Later the final cost and gredients is extracted from the graph with the gradients being unrolled ot match the parameters vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients are:\n",
      "(1, 'op1-Variable', array([[-2.97423341],\n",
      "       [-3.49364679]]))\n",
      "(3, 'op3-Variable', array([-6.30036239]))\n",
      "Unrolled gradients [-2.97423341 -3.49364679 -6.30036239]\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradients are:\")\n",
    "for g in mainGraph.getGradients():\n",
    "    print(g)\n",
    "print(\"Unrolled gradients\", mainGraph.unrollGradients())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass our function to a minimizer of choice, for now lets use the one in scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 9.847984166654734e-12\n",
      " hess_inv: array([[ 12.10980509,   0.39023944,  -5.64093334],\n",
      "       [  0.39023944,  12.28600029,  -6.53002646],\n",
      "       [ -5.64093334,  -6.53002646,   6.9053932 ]])\n",
      "      jac: array([ -1.75466966e-07,   7.62098485e-07,  -8.12225231e-07])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 12\n",
      "      nit: 9\n",
      "     njev: 12\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 2.00000294,  3.0000156 ,  3.99998975])\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize\n",
    "res = scipy.optimize.minimize(fprime,\n",
    "                              param0,\n",
    "                              args=(x, y),\n",
    "                              method=\"BFGS\",\n",
    "                              jac=True)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ML models, it is often useful to use stocastic gradient descent as your minimizer due to large number of datapoints. GraphAttack comes with a simple implementation of the Adam method that is considered quite robust. The details of the implementation can be found in\n",
    "https://arxiv.org/pdf/1412.6980.pdf\n",
    "\n",
    "Here we will simply use the minimizer, it can be initialized by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adamGrad = ga.adaptiveSGD(trainingData=x,\n",
    "                          trainingLabels=y,\n",
    "                          param0=param0,\n",
    "                          epochs=1e3,\n",
    "                          miniBatchSize=5,\n",
    "                          initialLearningRate=1e-3,\n",
    "                          beta1=0.9,\n",
    "                          beta2=0.999,\n",
    "                          epsilon=1e-8,\n",
    "                          testFrequency=1e1,\n",
    "                          function=fprime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the explanation below:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"Class that holds most of the funtionalities of the\n",
    "adaptive SGD, currently using the ADAM algorightm\n",
    "Attributes\n",
    "----------\n",
    "trainDataset : np.array\n",
    "    features for each example\n",
    "trainLabels : np.array\n",
    "    labels for each example\n",
    "param0 : np.array\n",
    "    Initial parameters\n",
    "epochs : int\n",
    "    number of epochs to run the minimizer\n",
    "miniBatchSize : int\n",
    "    size of the mini batch\n",
    "\n",
    "initialLearningRate : flooat\n",
    "    Initial learning rate (typical choice: 1e-3)\n",
    "beta1 : float\n",
    "    Beta1 Adam paramater (typical choice: 0.9)\n",
    "beta2 : float\n",
    "    Beta2 Adam parameter (typical choice: 0.999)\n",
    "epsilon : float\n",
    "    epsilon Adam parameter (typical choice: 1e-8)\n",
    "\n",
    "testFrequency : int\n",
    "    How many minibatches to average the cost over for testing\n",
    "function : float\n",
    "    Function to minimize that is of form\n",
    "    (cost, gradient) = function(params, FeaturesMatrix, LabelsMatrix)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimalization is performed by calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mibatch: 0 out of 20 from epoch: 0 out of 1000, iterCost is: 1.260852e-02\n",
      "Mibatch: 0 out of 20 from epoch: 100 out of 1000, iterCost is: 1.101159e+01\n",
      "Mibatch: 0 out of 20 from epoch: 200 out of 1000, iterCost is: 1.813191e+00\n",
      "Mibatch: 0 out of 20 from epoch: 300 out of 1000, iterCost is: 1.150450e-01\n",
      "Mibatch: 0 out of 20 from epoch: 400 out of 1000, iterCost is: 3.079652e-02\n",
      "Mibatch: 0 out of 20 from epoch: 500 out of 1000, iterCost is: 9.495015e-03\n",
      "Mibatch: 0 out of 20 from epoch: 600 out of 1000, iterCost is: 1.028337e-03\n",
      "Mibatch: 0 out of 20 from epoch: 700 out of 1000, iterCost is: 9.837792e-06\n",
      "Mibatch: 0 out of 20 from epoch: 800 out of 1000, iterCost is: 1.150255e-10\n",
      "Mibatch: 0 out of 20 from epoch: 900 out of 1000, iterCost is: 3.864496e-24\n",
      "[ 2.  3.  4.]\n"
     ]
    }
   ],
   "source": [
    "params = adamGrad.minimize(printTrainigCost=True)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License (MIT)\n",
    "\n",
    "Copyright (c) 2016 by [Magnus Erik Hvass Pedersen](http://www.hvass-labs.org/)\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
